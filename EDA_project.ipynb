{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VqxNyF1kLrGm"
      },
      "outputs": [],
      "source": [
        "!pip install sweetviz\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sweetviz as sv\n",
        "from scipy import stats\n",
        "import itertools\n",
        "from pandas.api.types import is_numeric_dtype\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcXOz0qfQgWZ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"death_prediction_synthetic.csv\")\n",
        "df.head(10) #first 10 rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUcFu9DRdEis"
      },
      "source": [
        "# First part - EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJv81Zv1phVu"
      },
      "source": [
        "## A - info\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gds33E0SXtfm"
      },
      "source": [
        "pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWCB1g-_RK1U"
      },
      "outputs": [],
      "source": [
        "df.info() #basic information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeK0uetxRcID"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "rkNXuuZd9uRV"
      },
      "outputs": [],
      "source": [
        "df.median(numeric_only=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FW4Q6OIYlHx"
      },
      "outputs": [],
      "source": [
        "report = sv.analyze(df)\n",
        "report.show_html(\"SweetViz_Report.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KpTw3upZMQK"
      },
      "outputs": [],
      "source": [
        "report.show_html(\"SweetViz_Report.html\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "AddA8wMt2ibH"
      },
      "outputs": [],
      "source": [
        "pd.isna(df).sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "3BQBabt9l3_d"
      },
      "outputs": [],
      "source": [
        "df.isna().mean()*100\n",
        "#we can see that data have differen % of NA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EKa8VXtjQZV"
      },
      "outputs": [],
      "source": [
        "numeric_data = [var for var in df.columns if len(df[var].unique()) > 5]\n",
        "char_data = [var for var in df.columns if len(df[var].unique()) <=5]\n",
        "\n",
        "numeric_data_df = df.select_dtypes(include=['number']).loc[:, ~df.isin([0, 1,2,3]).all()] #dataFR for only numeric data\n",
        "\n",
        "for var in char_data:\n",
        "    df[var] = df[var].astype('category')\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QX65Tqrl7_2"
      },
      "outputs": [],
      "source": [
        "len(numeric_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juQ--vE_iS_Y"
      },
      "outputs": [],
      "source": [
        "len(char_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIwKTcFZh2cT"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(9,5,figsize = (40,20))\n",
        "ax = ax.flatten()\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for i, var in enumerate(df.columns):\n",
        "\n",
        "    if var in numeric_data :\n",
        "        sns.histplot(data = df, x = var, ax = ax[i]).set(xlabel = None, ylabel = None, title = var)\n",
        "    else:\n",
        "        sns.countplot(x = df[var], ax = ax[i]).set(xlabel = None, ylabel = None, title = var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yY4VefAnOOZ"
      },
      "outputs": [],
      "source": [
        "# Create a new figure for each column. The same figures like in the previous code.\n",
        "for column in df.columns:\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    if column in numeric_data:\n",
        "        # Histogram and KDE for numeric data\n",
        "        sns.histplot(df[column], kde=True, color='blue', bins=20)\n",
        "        plt.title(f'Distribution of {column}')\n",
        "        plt.xlabel(column)\n",
        "        plt.ylabel('Frequency')\n",
        "    else:\n",
        "        # Barplot for categorical data\n",
        "        sns.countplot(x=df[column], palette=\"viridis\")\n",
        "        plt.title(f'Barplot of {column}')\n",
        "        plt.xlabel(column)\n",
        "        plt.ylabel('Count')\n",
        "\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOXdU9ReElJj"
      },
      "source": [
        "\n",
        "## B  -   Corr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8kMlMe0vvik"
      },
      "source": [
        "Correlation for numeric data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fMxXN0oqdB4"
      },
      "outputs": [],
      "source": [
        "pairs_num = list(itertools.combinations(numeric_data, 2))\n",
        "for col1, col2 in pairs_num:\n",
        "    x = df[col1]\n",
        "    y = df[col2]\n",
        "    corr, p = stats.spearmanr(x, y)\n",
        "    if corr < 0.05:\n",
        "        print(f\"{col1} and {col2}: Corr = {corr:.2f}, p-value = {p:.4f}\")\n",
        "#check where in numeric pairs corr > 0.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_jrhq6L4uFSu"
      },
      "outputs": [],
      "source": [
        "def plot_scatter(col1, col2, corr, p_value):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.scatterplot(data=df, x=col1, y=col2)\n",
        "    plt.title(f\"{col1} vs {col2}\\nCorr = {corr:.2f}, p-value = {p:.4f}\")\n",
        "    plt.xlabel(col1)\n",
        "    plt.ylabel(col2)\n",
        "    plt.show()\n",
        "\n",
        "for col1, col2 in pairs_num:\n",
        "    x = df[col1]\n",
        "    y = df[col2]\n",
        "    corr, p = stats.spearmanr(x, y)\n",
        "    if p < 0.05:\n",
        "      plot_scatter(col1, col2, corr, p)\n",
        "\n",
        "# the dot plot for each numeric pairs with significant correlation (p-value < 0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShrnYK22Qgly"
      },
      "outputs": [],
      "source": [
        "corr_mat = df.corr(numeric_only=True)\n",
        "\n",
        "sns.heatmap(corr_mat, cmap = 'viridis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1C_EffhpWVg"
      },
      "source": [
        "----------------------------------------------\n",
        "\n",
        "## C  -  Difference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LuUNxdj_J5s"
      },
      "source": [
        "Between categorical variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2D_xMqN45T-V"
      },
      "source": [
        "If the p-value < 0.05, the differences are considered statistically significant and the null hypothesis can be rejected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oyWgOvGtxaTO"
      },
      "outputs": [],
      "source": [
        "#cat for cat Chi-Square Test\n",
        "from scipy.stats import chi2_contingency\n",
        "pairs_char = list(itertools.combinations(char_data, 2))\n",
        "for col1, col2 in pairs_char:\n",
        "    contingency_table = pd.crosstab(df[col1], df[col2])\n",
        "    stat, p, dof, expected = chi2_contingency(contingency_table)\n",
        "    if p < 0.05:\n",
        "        print(f\"{col1} and {col2}: p-value = {p:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRc96Zrz2eHO"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "pairs_char = list(itertools.combinations(char_data, 2))\n",
        "for col1, col2 in pairs_char:\n",
        "    contingency_table = pd.crosstab(df[col1], df[col2])\n",
        "    stat, p, dof, expected = chi2_contingency(contingency_table)\n",
        "    if p == 0:\n",
        "        print(f\"{col1} and {col2}: p-value = {p}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "71Gimm6E0kgR"
      },
      "outputs": [],
      "source": [
        "def barplot_side_by_side(df, col1, col2, p):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    crosstab = pd.crosstab(df[col1], df[col2])\n",
        "    crosstab.plot(kind='bar', figsize=(8, 6), colormap='Set2', width=0.8, position=1)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.xlabel(col1)\n",
        "    plt.title(f\"{col1} vs {col2}\\np-value = {p:.4f}\")\n",
        "    plt.legend(title=col2, bbox_to_anchor=(1, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for col1, col2 in pairs_char:\n",
        "    contingency_table = pd.crosstab(df[col1], df[col2])\n",
        "    stat, p, dof, expected = chi2_contingency(contingency_table)\n",
        "    if p < 0.05:\n",
        "      barplot_side_by_side(df, col1, col2, p)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-NCZu_I7ce5"
      },
      "source": [
        "Between numerical and categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ne65WUnL2BBm"
      },
      "outputs": [],
      "source": [
        "counter = 1\n",
        "for col1 in numeric_data:\n",
        "    for col2 in char_data:\n",
        "        # Conducting an ANOVA test\n",
        "        groups = [df[df[col2] == code][col1] for code in df[col2].unique()]\n",
        "\n",
        "        if len(groups) > 1 and all(len(group) > 1 for group in groups):\n",
        "            f_stat, p_value = stats.f_oneway(*groups)\n",
        "            if p_value < 0.05:\n",
        "                print(f\"{counter}. ANOVA for {col1} and {col2}: F-statistic={f_stat:.2f}, p-value={p_value:.4f}\")\n",
        "                counter += 1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "e22sP7C0a1cj"
      },
      "outputs": [],
      "source": [
        "def plot_boxplot(col1, col2):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    df.boxplot(column=col1, by=col2, patch_artist=True)\n",
        "    plt.title(f'Boxplot of {col1} by {col2}')\n",
        "    plt.xlabel(col2)\n",
        "    plt.ylabel(col1)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for col1 in numeric_data:\n",
        "    for col2 in char_data:\n",
        "        # Conducting an ANOVA test\n",
        "        groups = [df[df[col2] == code][col1] for code in df[col2].unique()]\n",
        "\n",
        "        if len(groups) > 1 and all(len(group) > 1 for group in groups):\n",
        "            f_stat, p_value = stats.f_oneway(*groups)\n",
        "            if p_value < 0.05:\n",
        "              plot_boxplot(col1, col2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dqD2_JGE-P8"
      },
      "outputs": [],
      "source": [
        "def plot_distribution(col1, col2):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "\n",
        "\n",
        "    sns.displot(data=df, x=col1, hue=col2, kde=True, kind = \"hist\" , height=6, aspect=1.5, palette=\"Set2\")\n",
        "\n",
        "    plt.title(f'Distribution of {col1} by {col2}')\n",
        "    plt.xlabel(col1)\n",
        "    plt.ylabel(f'Density of {col1}')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for col1 in numeric_data:\n",
        "    for col2 in char_data:\n",
        "        # Conducting an ANOVA test\n",
        "        groups = [df[df[col2] == code][col1] for code in df[col2].unique()]\n",
        "\n",
        "        if len(groups) > 1 and all(len(group) > 1 for group in groups):\n",
        "            f_stat, p_value = stats.f_oneway(*groups)\n",
        "            if p_value < 0.05:\n",
        "                    plot_distribution(col1, col2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXCblYL7e9uN"
      },
      "source": [
        "## D - Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH0Qqr1qI5MU"
      },
      "outputs": [],
      "source": [
        "numeric_data_df = df.select_dtypes(include=['number']).loc[:, ~df.isin([0, 1,2,3]).all()] #dataFR for only numeric data\n",
        "\n",
        "q1 = numeric_data_df.quantile(0.25)\n",
        "q3 = numeric_data_df.quantile(0.75)\n",
        "IQR = q3 - q1\n",
        "L1 = q1 - 1.5*IQR\n",
        "L2 = q3 + 1.5*IQR\n",
        "outliers = (numeric_data_df <= L1) | (numeric_data_df >= L2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOLuTcqDM565"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(outliers)\n",
        "plt.title('Outliers', fontsize=16)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XkSHfQiNRis"
      },
      "outputs": [],
      "source": [
        "numeric_data_df[outliers].describe().T[['count', 'mean', 'min', 'max']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgLjMTpgNZ6I"
      },
      "outputs": [],
      "source": [
        "boundaries = pd.concat([L1, L2], axis=1)\n",
        "boundaries.columns = ['Lower_Bound', 'Upper_Bound']\n",
        "boundaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjZsnWLGY5YJ"
      },
      "outputs": [],
      "source": [
        "# the outliers shown in leuko_u are not outliers. we'll update the matrix\n",
        "# same with age\n",
        "outliers['leuko_u'] = False\n",
        "outliers['age'] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XRB_9qFZHSC"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(outliers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjQcl9T4MGhf"
      },
      "outputs": [],
      "source": [
        "red = dict(markerfacecolor='red', marker='o')\n",
        "def plot_boxplot(col1):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    df.boxplot(column=col1, patch_artist=True , flierprops=red)\n",
        "    plt.title(f'Boxplot of {col1}')\n",
        "    plt.ylabel(col1)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for col1 in df[numeric_data]:\n",
        "    if col1 != 'leuko_u' and col1 != 'age':\n",
        "      plot_boxplot(col1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTA3vgiOGdoc"
      },
      "source": [
        "## E - heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lv0Z8f31GkeC"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df.isna())\n",
        "plt.title('Missing Values Heatmap', fontsize=16)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvgYhbesMXHH"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnZtcVj4Mpyj"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRq9LEe3UHyz"
      },
      "source": [
        "# Second part - Data cleaning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RagkFC4CUTsv"
      },
      "source": [
        "## a. Outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hY-9EK2S7p7r"
      },
      "outputs": [],
      "source": [
        "\n",
        "from scipy.stats import norm\n",
        "\n",
        "def cocor(data1, target1, data2, target2):\n",
        "\n",
        "    # Removing missing values\n",
        "    target1 = target1[data1.notna()]\n",
        "    data1 = data1[data1.notna()]\n",
        "    target2 = target2[data2.notna()]\n",
        "    data2 = data2[data2.notna()]\n",
        "\n",
        "    # Calculating Spearman's correlation\n",
        "    correlation1 = data1.corr(target1, method='spearman')\n",
        "    correlation2 = data2.corr(target2, method='spearman')\n",
        "\n",
        "    # Calculating sample size\n",
        "    n1 = len(data1)\n",
        "    n2 = len(data2)\n",
        "\n",
        "    # Calculating z-statistic\n",
        "    correlation1_z = 0.5 * np.log((1 + correlation1) / (1 - correlation1))\n",
        "    correlation2_z = 0.5 * np.log((1 + correlation2) / (1 - correlation2))\n",
        "\n",
        "    se_diff_r = np.sqrt(1 / (n1 - 3) + 1 / (n2 - 3))\n",
        "    diff = correlation1_z - correlation2_z\n",
        "    z = abs(diff / se_diff_r)\n",
        "\n",
        "    # Calculating p-value\n",
        "    p = (1 - norm.cdf(z)) * 2\n",
        "\n",
        "    return z, p\n",
        "\n",
        "def is_lower(p):\n",
        "    return p<0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdWeDeyN_ZAp"
      },
      "outputs": [],
      "source": [
        "# test distrtibutions\n",
        "from scipy import stats\n",
        "\n",
        "p_values_corr = {}\n",
        "\n",
        "# test correlations\n",
        "for j, col in enumerate(numeric_data):\n",
        "\n",
        "    s = df[col]\n",
        "    y = df['dead_5y']\n",
        "\n",
        "    s_withot_outliers = df.loc[~outliers[col], col]\n",
        "    y_withot_outliers = df.loc[~outliers[col], 'dead_5y']\n",
        "\n",
        "    _,p = cocor(s , y , s_withot_outliers, y_withot_outliers)\n",
        "    p_values_corr[col] = [p]\n",
        "\n",
        "decision_table = pd.DataFrame(p_values_corr).T\n",
        "decision_table.columns = ['p_value_correlation']\n",
        "\n",
        "correlation_changed = decision_table['p_value_correlation'].apply(is_lower)\n",
        "decision_table['correlation_changed'] = correlation_changed\n",
        "\n",
        "# test distrtibutions\n",
        "\n",
        "for j, col in enumerate(numeric_data):\n",
        "    s = df[col]\n",
        "    s = s[s.notna()]\n",
        "    s_withot_outliers = df.loc[~outliers[col], col]\n",
        "    s_withot_outliers = s_withot_outliers[s_withot_outliers.notna()]\n",
        "\n",
        "    _,p = stats.kstest(s,s_withot_outliers)\n",
        "\n",
        "    p_values_corr[col] = [p]\n",
        "\n",
        "decision_table['p_value_distrtibutions'] = pd.DataFrame(p_values_corr).T\n",
        "\n",
        "distribution_changed = decision_table['p_value_distrtibutions'].apply(is_lower)\n",
        "decision_table['distribution_changed'] = distribution_changed\n",
        "\n",
        "decision_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whC22hAZ_d0p"
      },
      "outputs": [],
      "source": [
        "# creating the decision column\n",
        "decision_table['drop'] = decision_table['correlation_changed'] ^ decision_table['distribution_changed']\n",
        "\n",
        "decision_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjL7vQqk_gKs"
      },
      "outputs": [],
      "source": [
        "col_to_drop = decision_table[decision_table['drop']].index\n",
        "col_to_drop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Fu2LE63_gpt"
      },
      "outputs": [],
      "source": [
        "count_before_nan = df.count()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSQUXta1_iZb"
      },
      "outputs": [],
      "source": [
        "df[outliers[col_to_drop]]=np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhfUx8iU_ku9"
      },
      "outputs": [],
      "source": [
        "count_after_nan = df.count()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22-vNC9s_ovy"
      },
      "outputs": [],
      "source": [
        "count_before_nan - count_after_nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TtLbTv6_t3e"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(outliers[col_to_drop])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJk_dVg9_372"
      },
      "source": [
        "## b. Missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lY9z-DcR1C0W"
      },
      "outputs": [],
      "source": [
        "missing_count = df.isnull().sum()\n",
        "\n",
        "missing_ratio = (missing_count / len(df)).sort_values(ascending=False)\n",
        "\n",
        "print(\"Missing values ratio by column:\")\n",
        "print(missing_ratio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9kmsiVL3KJE"
      },
      "outputs": [],
      "source": [
        "#1.Columns with more than 70% missing values will be removed.\n",
        "#deleting cols that have more than 70% missing values\n",
        "\n",
        "columns_to_drop = missing_ratio[missing_ratio >= 0.7].index\n",
        "\n",
        "print(\"Columns to be dropped due to high missing value ratio:\")\n",
        "print(columns_to_drop)\n",
        "\n",
        "\n",
        "df.drop(columns_to_drop, axis = 1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdoeRTEu3QcS"
      },
      "outputs": [],
      "source": [
        "#2.\n",
        "#converting variables with 40%-70% missing values to categorical variables\n",
        "cols_to_categorize = missing_ratio[(missing_ratio >= 0.4) & (missing_ratio < 0.7)].index\n",
        "print(\"Columns with missing ratio between 40% and 70%:\")\n",
        "print(cols_to_categorize)\n",
        "\n",
        "for col in cols_to_categorize:\n",
        "    if col in numeric_data:\n",
        "        # Dividing the values into 4 categories\n",
        "        df[col] = pd.qcut(df[col], 4, labels=[1, 2, 3, 4], duplicates='drop')\n",
        "\n",
        "        # Converting the column to categorical and adding category 0\n",
        "        df[col] = df[col].astype('category')\n",
        "        df[col] = df[col].cat.add_categories([0])\n",
        "        df[col].fillna(0, inplace=True)\n",
        "\n",
        "       # Updating the lists of variables\n",
        "        numeric_data.remove(col)\n",
        "        char_data.append(col)\n",
        "\n",
        "    if col in char_data:\n",
        "\n",
        "        # Checking if the first value in the categories is 0\n",
        "        if df[col].cat.categories[0] == 0:\n",
        "            # Adding 1 to all categories\n",
        "            df[col] = df[col].apply(lambda x: x + 1 if not pd.isnull(x) else x)\n",
        "\n",
        "        # Adding category 0 for missing values\n",
        "        df[col] = df[col].cat.add_categories([0])\n",
        "        df[col].fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WU29c4QW3ezk"
      },
      "source": [
        "we see that we dont have variables with 40%-70% missing values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8FHU6pE4xrg"
      },
      "outputs": [],
      "source": [
        "#3.\n",
        "#checking if the missing values are MCAR (Missing Completely at Random) or MAR (Missing at Random).\n",
        "\n",
        "cols_to_check = missing_ratio[(missing_ratio > 0) & (missing_ratio < 0.4)].index\n",
        "\n",
        "p_values = {}\n",
        "\n",
        "for missing_col in cols_to_check:\n",
        "    p_values[missing_col] = {}\n",
        "\n",
        "    for col in df.columns:\n",
        "        if missing_col != col:\n",
        "\n",
        "            if col in numeric_data:\n",
        "                s1 = df[col]\n",
        "                s2 = s1[df[missing_col].notnull()]\n",
        "                _, p = stats.kstest(s1, s2)\n",
        "\n",
        "            else:\n",
        "                s1 = df[missing_col].isnull().astype(int)\n",
        "                s2 = df[col]\n",
        "                _, p, _, _ = stats.chi2_contingency(pd.crosstab(s1, s2))\n",
        "\n",
        "            p_values[missing_col][col] = p\n",
        "\n",
        "p_values_df = pd.DataFrame(p_values).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZmlEdlIGBY-"
      },
      "source": [
        "Significant values ​​(p < 0.05) indicate that the missing_col values ​​depend on another variable (col)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LI1Yh3cx5jTD"
      },
      "outputs": [],
      "source": [
        "# True - indicates a significant relationship between the missing values in the column and the column being tested.\n",
        "p_values_df = pd.DataFrame(p_values).T\n",
        "p_values_df = p_values_df <= 0.05\n",
        "p_values_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4QbAKks5zzl"
      },
      "outputs": [],
      "source": [
        "p_values_df['num_of_affecting_columns'] = (p_values_df).sum(axis=1)\n",
        "p_values_df['MCAR'] = p_values_df['num_of_affecting_columns'] == 0\n",
        "p_values_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H05HdR8kHw9m"
      },
      "source": [
        "so theres no Missing Completely At Random values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nkx7eAYMGyAS"
      },
      "outputs": [],
      "source": [
        "# We will divide the features into two groups:MCAR and Not MCAR\n",
        "cols_to_impute = list(p_values_df.query('MCAR == True').index)\n",
        "cols_to_categorize = list(p_values_df.query('MCAR == False').index)\n",
        "\n",
        "# imputation (MCAR)\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=3)\n",
        "for col in cols_to_impute:\n",
        "    df[col] = imputer.fit_transform(np.array(df[col]).reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geal_FLTCSZm"
      },
      "outputs": [],
      "source": [
        "# for leuko_u, we'll convert to categorica\n",
        "df.leuko_u = df.leuko_u.astype('category')\n",
        "numeric_data.remove('leuko_u')\n",
        "char_data.append('leuko_u')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ry3BoAuJPjZW"
      },
      "outputs": [],
      "source": [
        "df.Charlson = df.Charlson.astype('category')\n",
        "numeric_data.remove('Charlson')\n",
        "char_data.append('Charlson')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_P18X2DeGLjm"
      },
      "outputs": [],
      "source": [
        "# categorize (NOT MCAR)\n",
        "for col in cols_to_categorize:\n",
        "    if col in numeric_data:\n",
        "        df[col] = pd.qcut(df[col], 4, labels=[1, 2, 3, 4])\n",
        "        df[col] = df[col].astype('category')\n",
        "\n",
        "        if 0 not in df[col].cat.categories:\n",
        "            df[col] = df[col].cat.add_categories([0])\n",
        "        df[col].fillna(0, inplace=True)\n",
        "        numeric_data.remove(col)\n",
        "        char_data.append(col)\n",
        "    else:\n",
        "\n",
        "        if 0 not in df[col].cat.categories:\n",
        "            df[col] = df[col].cat.add_categories([0])\n",
        "\n",
        "        df[col].fillna(0, inplace=True)\n",
        "\n",
        "\n",
        "        if 0 in df[col].cat.categories:\n",
        "            df[col] = df[col].apply(lambda x: x + 1 if pd.notna(x) else x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ULYDnKCIJDaM"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGasU0TfP1rg"
      },
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXm-FKFK_jD7"
      },
      "source": [
        "## c. we remove one column from two where the correlation is bigger than 0.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "U8Aug2D5_u2b"
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=['weigh', 'LDL', 'HbA1c'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqmhGyhemXZI",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df = df.drop(columns=['residence', 'smoking_status']) # same values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ftnlT4HMD6if"
      },
      "outputs": [],
      "source": [
        "\n",
        "numeric_data = [var for var in df.columns if len(df[var].unique()) > 5]\n",
        "char_data = [var for var in df.columns if len(df[var].unique()) <=5]\n",
        "numeric_data_df = df.select_dtypes(include=['number']).loc[:, ~df.isin([0, 1,2,3]).all()] #dataFR for only numeric data\n",
        "pairs_num = list(itertools.combinations(numeric_data, 2))\n",
        "pairs_char = list(itertools.combinations(char_data, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_Frid249ZqX"
      },
      "outputs": [],
      "source": [
        "duplicates = df.duplicated()\n",
        "num_duplicates = duplicates.sum()\n",
        "print(f\"number of duplicates: {num_duplicates}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdONSuXgRQFy"
      },
      "source": [
        "## download file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p4-D6z-5cDld"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"death_prediction_synthetic_after_outliers_and_missingvalues_removal.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqE6jM2Ddyj_"
      },
      "source": [
        "# Third part - EDA circular"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kHMNC9cHM6N"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iq-XCw16HPOY"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4HMV51jHRtO"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(9,5,figsize = (40,20))\n",
        "ax = ax.flatten()\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "for i, var in enumerate(df.columns):\n",
        "\n",
        "    if var in numeric_data :\n",
        "        sns.histplot(data = df, x = var, ax = ax[i]).set(xlabel = None, ylabel = None, title = var)\n",
        "    else:\n",
        "        sns.countplot(x = df[var], ax = ax[i]).set(xlabel = None, ylabel = None, title = var)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nr-9V0YGHhs6"
      },
      "outputs": [],
      "source": [
        "for col1, col2 in pairs_num:\n",
        "    x = df[col1]\n",
        "    y = df[col2]\n",
        "    corr, p = stats.spearmanr(x, y)\n",
        "    if p < 0.05:\n",
        "      plot_scatter(col1, col2, corr, p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ot6aNJJSHaOO"
      },
      "outputs": [],
      "source": [
        "corr_mat = df.corr(numeric_only=True)\n",
        "\n",
        "sns.heatmap(corr_mat, cmap = 'viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOE1w08GHnv1"
      },
      "outputs": [],
      "source": [
        "for col1, col2 in pairs_char:\n",
        "    contingency_table = pd.crosstab(df[col1], df[col2])\n",
        "    stat, p, dof, expected = chi2_contingency(contingency_table)\n",
        "    if p < 0.05:\n",
        "      barplot_side_by_side(df, col1, col2, p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fpyRYK6HuqA"
      },
      "outputs": [],
      "source": [
        "def plot_boxplot(col1, col2):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    df.boxplot(column=col1, by=col2, patch_artist=True)\n",
        "    plt.title(f'Boxplot of {col1} by {col2}')\n",
        "    plt.xlabel(col2)\n",
        "    plt.ylabel(col1)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "for col1 in numeric_data:\n",
        "    for col2 in char_data:\n",
        "        # Conducting an ANOVA test\n",
        "        groups = [df[df[col2] == code][col1] for code in df[col2].unique()]\n",
        "\n",
        "        if len(groups) > 1 and all(len(group) > 1 for group in groups):\n",
        "            f_stat, p_value = stats.f_oneway(*groups)\n",
        "            if p_value < 0.05:\n",
        "              plot_boxplot(col1, col2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1-tGKzFe-fr"
      },
      "source": [
        "# Fourth part - Adding data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5AH8etJBLAB"
      },
      "outputs": [],
      "source": [
        "#we add a new column that shows what medications a person takes (by the first letters of the variable)\n",
        "\n",
        "\n",
        "conditions = [\n",
        "    (df['antidiabetics'] == 1) & (df['cardiovascular_meds'] == 1) & (df['statines'] == 1),\n",
        "    (df['antidiabetics'] == 1) & (df['cardiovascular_meds'] == 1),\n",
        "    (df['antidiabetics'] == 1) & (df['statines'] == 1),\n",
        "    (df['cardiovascular_meds'] == 1) & (df['statines'] == 1),\n",
        "    (df['antidiabetics'] == 1),\n",
        "    (df['cardiovascular_meds'] == 1),\n",
        "    (df['statines'] == 1),\n",
        "]\n",
        "\n",
        "\n",
        "values = ['ACS', 'AC', 'AS', 'CS', 'A', 'C', 'S']\n",
        "\n",
        "\n",
        "df['medication_count'] = np.select(conditions, values, default='None')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pw7_A7nABakr"
      },
      "outputs": [],
      "source": [
        "#Metabolic syndrome risk: Based on factors such as obesity (BMI), high blood pressure (bp_sys, bp_dias), high cholesterol (cholesterol_total).\n",
        "\n",
        "\n",
        "BMI = df['BMI'].to_numpy()\n",
        "bp_sys = df['bp_sys'].to_numpy()\n",
        "bp_dias = df['bp_dias'].to_numpy()\n",
        "triglycerides = df['triglycerides'].to_numpy()\n",
        "HDL = df['HDL'].to_numpy()\n",
        "glucose = df['glucose'].to_numpy()\n",
        "sex = df['sex'].to_numpy()\n",
        "\n",
        "\n",
        "obesity = BMI >= 30\n",
        "high_bp = (bp_sys >= 130) | (bp_dias >= 85)\n",
        "high_triglycerides = triglycerides >= 150\n",
        "low_hdl = ((sex == 1) & (HDL < 40)) | ((sex == 0) & (HDL < 50))\n",
        "high_glucose = glucose >= 100\n",
        "\n",
        "\n",
        "risk_factors = obesity + high_bp + high_triglycerides + low_hdl + high_glucose\n",
        "\n",
        "# Assign 1 if >= 3 criteria, otherwise 0\n",
        "metabolic_risk = np.where(risk_factors >= 3, 1, 0)\n",
        "\n",
        "\n",
        "df['metabolic_risk'] = metabolic_risk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d--Mpf5xFLZW"
      },
      "outputs": [],
      "source": [
        "#Systolic and diastolic pressure (bp_sys, bp_dias): a variable that indicates the presence of hypertension.\n",
        "\n",
        "bp_sys = df['bp_sys'].to_numpy()\n",
        "bp_dias = df['bp_dias'].to_numpy()\n",
        "\n",
        "# We define the risk: 1 = there is a risk, 0 = no risk\n",
        "risk = np.where((bp_sys >= 130) | (bp_dias >= 85), 1, 0)\n",
        "\n",
        "\n",
        "df['blood_pressure_risk'] = risk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grgXD6ZCJtms"
      },
      "outputs": [],
      "source": [
        "q1 = numeric_data_df.quantile(0.25)\n",
        "q3 = numeric_data_df.quantile(0.75)\n",
        "IQR = q3 - q1\n",
        "L1 = q1 - 1.5*IQR\n",
        "L2 = q3 + 1.5*IQR\n",
        "outliers = (numeric_data_df <= L1) | (numeric_data_df >= L2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6Tv3gbJKzz6"
      },
      "outputs": [],
      "source": [
        "outliers['leuko_u'] = False\n",
        "outliers['age'] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2tIc4RsLCM0"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(outliers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xauDIv9aJuNn"
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAH-Xg10EU8J"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PldNb5bRHqI"
      },
      "source": [
        "## download file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pC0JJ9ewQ-7a"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"death_prediction_synthetic_after_adding_data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJkVM6_tfEvQ"
      },
      "source": [
        "# Fifth part - Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFfu1NCrJOjz"
      },
      "outputs": [],
      "source": [
        "# feature Selection - filtering method\n",
        "\n",
        "p_values = []\n",
        "columns = list(df.columns)\n",
        "columns.remove('dead_5y')\n",
        "\n",
        "for var in columns:\n",
        "\n",
        "\n",
        "    if var in numeric_data:\n",
        "\n",
        "        x1 = df.query('dead_5y == 1')[var]\n",
        "        x2 = df.query('dead_5y == 0')[var]\n",
        "\n",
        "        _ , p = stats.mannwhitneyu(x1,x2)\n",
        "\n",
        "    else:\n",
        "        _ , p, _ , _ = stats.chi2_contingency(pd.crosstab(df[var], df.dead_5y))\n",
        "\n",
        "    p_values.append(p)\n",
        "\n",
        "selection = pd.DataFrame(p_values, index = columns, columns=['p_value'])\n",
        "selection['keep'] = ['yes' if p <= 0.05 else 'no' for p in selection.p_value]\n",
        "selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLcON-1sJ-Ha"
      },
      "outputs": [],
      "source": [
        "selection.query(\"keep == 'yes'\")\n",
        "cols_to_drop = selection.query(\"keep == 'no'\").index\n",
        "df.drop(cols_to_drop, axis =1, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iz-aBX318xK"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "# Target variable\n",
        "target = 'dead_5y'\n",
        "\n",
        "# Separate numeric and categorical features\n",
        "numeric_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "# 1. Correlation for numeric variables (if target is numeric)\n",
        "correlation_matrix = df[numeric_features].corr()\n",
        "print(\"\\nCorrelation matrix:\\n\", correlation_matrix)\n",
        "\n",
        "# Visualize the correlation\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation matrix\")\n",
        "plt.show()\n",
        "\n",
        "# 2. Visualize the distribution of numeric variables\n",
        "for feature in numeric_features:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.boxplot(x=target, y=feature, data=df)\n",
        "    plt.title(f'Distribution of {feature} by target variable')\n",
        "    plt.show()\n",
        "\n",
        "# 3. Analysis of categorical variables\n",
        "for feature in categorical_features:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.countplot(x=feature, hue=target, data=df)\n",
        "    plt.title(f'Distribution of {feature} by target variable')\n",
        "    plt.show()\n",
        "\n",
        "    # Statistical test for categorical variables (Chi-square)\n",
        "    crosstab = pd.crosstab(df[feature], df[target])\n",
        "    chi2, p, _, _ = chi2_contingency(crosstab)\n",
        "    print(f\"\\nChi-square test for {feature}: p-value = {p}\")\n",
        "    if p < 0.05:\n",
        "        print(f\"Variable {feature} is statistically significantly associated with the target variable.\")\n",
        "    else:\n",
        "        print(f\"Variable {feature} is not statistically significant for the target variable.\")\n",
        "\n",
        "# 4. Grouping by categories and calculating statistics\n",
        "for feature in categorical_features:\n",
        "    grouped = df.groupby(feature)[target].count()\n",
        "    print(f\"\\nAverage death probability for different categories of {feature}:\\n\", grouped)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "XKMWCSFJyNsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"death_prediction_synthetic_final.csv\")"
      ],
      "metadata": {
        "id": "FAb264SQHXKi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}